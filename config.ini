[DEFAULT]
MAX_LENGTH = 25

<<<<<<< HEAD
batch_size = 32
hidden_size = 500
=======
batch_size = 64
hidden_size = 256
>>>>>>> 3c6e1ae323ca9b05f7044ab03b279843754d6ba1

encoder_n_layers = 2
decoder_n_layers = 4

number_iters = 10000
<<<<<<< HEAD
PRINT_EVERY = 500
=======
PRINT_EVERY = 100
>>>>>>> 3c6e1ae323ca9b05f7044ab03b279843754d6ba1
SAVE_EVERY =  2000

learning_rate = 0.0001
decoder_learning_rate = 5.0
<<<<<<< HEAD
teacher_forcing_ratio = 0.86
=======
teacher_forcing_ratio = 0.8
>>>>>>> 3c6e1ae323ca9b05f7044ab03b279843754d6ba1

dropout = 0.1

corpus = custom
save_dir = save

[evaluator]
probability = 0.85
threshold = 0.92

[data]
<<<<<<< HEAD
samples = 2000
vocab_size = 20000
=======
samples = 1000
vocab_size = 10000
>>>>>>> 3c6e1ae323ca9b05f7044ab03b279843754d6ba1
data_path = data
in_data = custom.enc,train.from
out_data = custom.dec,train.to
